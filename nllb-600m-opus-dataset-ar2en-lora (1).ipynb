{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets sacrebleu \n!pip install evaluate       \n!pip install peft\n!pip install rouge_score\n!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:56:51.076091Z","iopub.execute_input":"2024-07-31T21:56:51.076797Z","iopub.status.idle":"2024-07-31T21:58:06.972832Z","shell.execute_reply.started":"2024-07-31T21:56:51.076763Z","shell.execute_reply":"2024-07-31T21:58:06.971620Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m848.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.10.1 sacrebleu-2.4.2\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=fa22ae3e031a8190802e0cfbfabffa992e2ef35d823db29babfb56eef2121f4e\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"NLLB\"\nos.environ[\"WANDB_NOTES\"] = \"Fine tune NLLB\"\nos.environ[\"WANDB_NAME\"] = \"finetune-NLLB-600M-on-opus100-Ar2En-with-lora\"","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:58:06.974842Z","iopub.execute_input":"2024-07-31T21:58:06.975212Z","iopub.status.idle":"2024-07-31T21:58:08.491332Z","shell.execute_reply.started":"2024-07-31T21:58:06.975170Z","shell.execute_reply":"2024-07-31T21:58:08.490172Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import get_dataset_config_names\n\nconfigs=get_dataset_config_names(\"opus100\")\nprint(configs)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:58:08.492466Z","iopub.execute_input":"2024-07-31T21:58:08.492736Z","iopub.status.idle":"2024-07-31T21:58:26.039416Z","shell.execute_reply.started":"2024-07-31T21:58:08.492712Z","shell.execute_reply":"2024-07-31T21:58:26.038461Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a86b9400f0c448a585ec5e0d7151847a"}},"metadata":{}},{"name":"stdout","text":"['af-en', 'am-en', 'an-en', 'ar-de', 'ar-en', 'ar-fr', 'ar-nl', 'ar-ru', 'ar-zh', 'as-en', 'az-en', 'be-en', 'bg-en', 'bn-en', 'br-en', 'bs-en', 'ca-en', 'cs-en', 'cy-en', 'da-en', 'de-en', 'de-fr', 'de-nl', 'de-ru', 'de-zh', 'dz-en', 'el-en', 'en-eo', 'en-es', 'en-et', 'en-eu', 'en-fa', 'en-fi', 'en-fr', 'en-fy', 'en-ga', 'en-gd', 'en-gl', 'en-gu', 'en-ha', 'en-he', 'en-hi', 'en-hr', 'en-hu', 'en-hy', 'en-id', 'en-ig', 'en-is', 'en-it', 'en-ja', 'en-ka', 'en-kk', 'en-km', 'en-kn', 'en-ko', 'en-ku', 'en-ky', 'en-li', 'en-lt', 'en-lv', 'en-mg', 'en-mk', 'en-ml', 'en-mn', 'en-mr', 'en-ms', 'en-mt', 'en-my', 'en-nb', 'en-ne', 'en-nl', 'en-nn', 'en-no', 'en-oc', 'en-or', 'en-pa', 'en-pl', 'en-ps', 'en-pt', 'en-ro', 'en-ru', 'en-rw', 'en-se', 'en-sh', 'en-si', 'en-sk', 'en-sl', 'en-sq', 'en-sr', 'en-sv', 'en-ta', 'en-te', 'en-tg', 'en-th', 'en-tk', 'en-tr', 'en-tt', 'en-ug', 'en-uk', 'en-ur', 'en-uz', 'en-vi', 'en-wa', 'en-xh', 'en-yi', 'en-yo', 'en-zh', 'en-zu', 'fr-nl', 'fr-ru', 'fr-zh', 'nl-ru', 'nl-zh', 'ru-zh']\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset=load_dataset(\"opus100\", \"ar-en\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:58:26.042127Z","iopub.execute_input":"2024-07-31T21:58:26.043118Z","iopub.status.idle":"2024-07-31T21:59:00.539439Z","shell.execute_reply.started":"2024-07-31T21:58:26.043090Z","shell.execute_reply":"2024-07-31T21:59:00.538556Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/214k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81b096ad309c4a809c04324e55582371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/99.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662205997f7e446d8172feae494e1007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/979k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2bc78e43e443c5b47a201246fa3a82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aed91298f614dc08f4208f16a3125c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f65b860b4745ce89c6f9e6bd60766c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6566f92ce9fe46e1a4114ed8f133d132"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2000\n    })\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1000000\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import NllbTokenizerFast\nimport torch\nmodel_name=\"facebook/nllb-200-distilled-600M\"\n\ntokenizer = NllbTokenizerFast.from_pretrained(\n        \"facebook/nllb-200-distilled-1.3B\", src_lang=\"Arabic\", tgt_lang=\"English\", load_in_8bit=True, device_map={'':torch.cuda.current_device()}\n    )\n# model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:59:00.540483Z","iopub.execute_input":"2024-07-31T21:59:00.540768Z","iopub.status.idle":"2024-07-31T21:59:15.972569Z","shell.execute_reply.started":"2024-07-31T21:59:00.540742Z","shell.execute_reply":"2024-07-31T21:59:15.971733Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b98b1456ed408abdc566509840a497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275f8668112c4500aac99538419392e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90577730a4a44aa886da7acefe68626e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1570de52f2403aba15697405a7cf47"}},"metadata":{}}]},{"cell_type":"code","source":"# use a sample of around 2000 instead of the complete dataset as training dataset\ntrain_dataset=dataset['train'].shuffle(seed=42).select(range(7000))\n\n# as evaluation dataset\neval_dataset=dataset['validation']\n\n\ndef preprocess_func(data):\n    inputs=[ex['ar'] for ex in data['translation']]\n    targets=[ex['en'] for ex in data['translation']]\n    \n    # tokenize each row of inputs and outputs\n    model_inputs=tokenizer(inputs, truncation=True)\n    labels=tokenizer(targets, truncation=True)\n    \n    model_inputs[\"labels\"]=labels[\"input_ids\"]\n    return model_inputs\n\n\n# We tokenize the entire dataset  \n\ntrain_dataset=train_dataset.map(preprocess_func, batched=True)\neval_dataset=eval_dataset.map(preprocess_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:59:15.973861Z","iopub.execute_input":"2024-07-31T21:59:15.974345Z","iopub.status.idle":"2024-07-31T21:59:19.956851Z","shell.execute_reply.started":"2024-07-31T21:59:15.974319Z","shell.execute_reply":"2024-07-31T21:59:19.955871Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05056f96dd2c4ca8a9e8308ffd0cccc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96efbb7eb3c40bf8a8660619a11171a"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftModel, prepare_model_for_kbit_training, PeftConfig, get_peft_model, LoraConfig, TaskType\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AutoModelForSeq2SeqLM\n\nbnb_config=BitsAndBytesConfig(\n    load_in_8bit=True\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name, quantization_config=bnb_config, device_map={'':torch.cuda.current_device()})","metadata":{"execution":{"iopub.status.busy":"2024-07-31T21:59:19.958034Z","iopub.execute_input":"2024-07-31T21:59:19.958325Z","iopub.status.idle":"2024-07-31T22:01:25.986461Z","shell.execute_reply.started":"2024-07-31T21:59:19.958299Z","shell.execute_reply":"2024-07-31T22:01:25.985347Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9489a5ca06c4c0da35fa47caf543235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b833447d8b1430aabc0dbba207c51c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc428aa022f549b297107a032b6c240e"}},"metadata":{}}]},{"cell_type":"code","source":"peft_config = LoraConfig(\n        target_modules=['q_proj','v_proj'], task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n    )\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:25.987782Z","iopub.execute_input":"2024-07-31T22:01:25.988095Z","iopub.status.idle":"2024-07-31T22:01:26.134565Z","shell.execute_reply.started":"2024-07-31T22:01:25.988068Z","shell.execute_reply":"2024-07-31T22:01:26.133574Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"trainable params: 1,179,648 || all params: 616,253,440 || trainable%: 0.1914\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model.config)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:26.136040Z","iopub.execute_input":"2024-07-31T22:01:26.136750Z","iopub.status.idle":"2024-07-31T22:01:26.143081Z","shell.execute_reply.started":"2024-07-31T22:01:26.136715Z","shell.execute_reply":"2024-07-31T22:01:26.142124Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"M2M100Config {\n  \"_name_or_path\": \"facebook/nllb-200-distilled-600M\",\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"relu\",\n  \"architectures\": [\n    \"M2M100ForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"bos_token_id\": 0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0,\n  \"decoder_layers\": 12,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0,\n  \"encoder_layers\": 12,\n  \"eos_token_id\": 2,\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"max_length\": 200,\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"m2m_100\",\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"quantization_config\": {\n    \"_load_in_4bit\": false,\n    \"_load_in_8bit\": true,\n    \"bnb_4bit_compute_dtype\": \"float32\",\n    \"bnb_4bit_quant_storage\": \"uint8\",\n    \"bnb_4bit_quant_type\": \"fp4\",\n    \"bnb_4bit_use_double_quant\": false,\n    \"llm_int8_enable_fp32_cpu_offload\": false,\n    \"llm_int8_has_fp16_weight\": false,\n    \"llm_int8_skip_modules\": null,\n    \"llm_int8_threshold\": 6.0,\n    \"load_in_4bit\": false,\n    \"load_in_8bit\": true,\n    \"quant_method\": \"bitsandbytes\"\n  },\n  \"scale_embedding\": true,\n  \"tokenizer_class\": \"NllbTokenizer\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 256206\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:26.146984Z","iopub.execute_input":"2024-07-31T22:01:26.147344Z","iopub.status.idle":"2024-07-31T22:01:26.162939Z","shell.execute_reply.started":"2024-07-31T22:01:26.147317Z","shell.execute_reply":"2024-07-31T22:01:26.162028Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): M2M100ForConditionalGeneration(\n      (model): M2M100Model(\n        (shared): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n        (encoder): M2M100Encoder(\n          (embed_tokens): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n          (embed_positions): M2M100SinusoidalPositionalEmbedding()\n          (layers): ModuleList(\n            (0-11): 12 x M2M100EncoderLayer(\n              (self_attn): M2M100Attention(\n                (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n              )\n              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (activation_fn): ReLU()\n              (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n              (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n        (decoder): M2M100Decoder(\n          (embed_tokens): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n          (embed_positions): M2M100SinusoidalPositionalEmbedding()\n          (layers): ModuleList(\n            (0-11): 12 x M2M100DecoderLayer(\n              (self_attn): M2M100Attention(\n                (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n              )\n              (activation_fn): ReLU()\n              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (encoder_attn): M2M100Attention(\n                (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                (v_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (q_proj): lora.Linear8bitLt(\n                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.1, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1024, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=1024, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n              )\n              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n              (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nimport sacrebleu\n\nmetric_bleu = evaluate.load(\"sacrebleu\")\nmetric_rouge = evaluate.load(\"rouge\")\n\n# Define a function to postprocess text\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\n# Define a function to compute metrics\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    \n    # Compute BLEU score\n    result_bleu = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n    result_bleu = {\"bleu\": result_bleu[\"score\"]}\n#     references=decoded_labels\n#     result_bleu = sacrebleu.corpus_bleu(translations=decoded_preds,[references])  \n#     result_bleu = {\"bleu\": round(bleu.score, 2)}\n    \n    # Compute ROUGE score\n    result_rouge = metric_rouge.compute(predictions=decoded_preds, references=decoded_labels)\n    result_rouge = {\"rouge\": result_rouge[\"rougeL\"]}\n    \n    # Combine BLEU and ROUGE results\n    result = {**result_bleu, **result_rouge}\n    \n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    \n    # Save the result to a file after each evaluation\n    with open('metrics.txt', 'a') as f:\n        f.write(f\"BLEU: {result['bleu']}, ROUGE: {result['rouge']}, Gen Len: {result['gen_len']}\\n\")\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:26.164023Z","iopub.execute_input":"2024-07-31T22:01:26.164309Z","iopub.status.idle":"2024-07-31T22:01:45.489073Z","shell.execute_reply.started":"2024-07-31T22:01:26.164284Z","shell.execute_reply":"2024-07-31T22:01:45.487997Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2024-07-31 22:01:28.783576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-31 22:01:28.783683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-31 22:01:28.910299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6febc87280d44b18e6b3a16c7f6258f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf1d5d7851148f09006212e1eb4fbcf"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:45.490559Z","iopub.execute_input":"2024-07-31T22:01:45.491362Z","iopub.status.idle":"2024-07-31T22:01:45.496616Z","shell.execute_reply.started":"2024-07-31T22:01:45.491325Z","shell.execute_reply":"2024-07-31T22:01:45.495390Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # Should print True if CUDA is available","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:45.497964Z","iopub.execute_input":"2024-07-31T22:01:45.498278Z","iopub.status.idle":"2024-07-31T22:01:45.511307Z","shell.execute_reply.started":"2024-07-31T22:01:45.498242Z","shell.execute_reply":"2024-07-31T22:01:45.510426Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"!export CUDA_LAUNCH_BLOCKING=1","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:45.512569Z","iopub.execute_input":"2024-07-31T22:01:45.512860Z","iopub.status.idle":"2024-07-31T22:01:46.603123Z","shell.execute_reply.started":"2024-07-31T22:01:45.512816Z","shell.execute_reply":"2024-07-31T22:01:46.601853Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:01:46.604847Z","iopub.execute_input":"2024-07-31T22:01:46.605284Z","iopub.status.idle":"2024-07-31T22:01:46.610738Z","shell.execute_reply.started":"2024-07-31T22:01:46.605242Z","shell.execute_reply":"2024-07-31T22:01:46.609781Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainerCallback, Seq2SeqTrainer, Seq2SeqTrainingArguments, Trainer, get_linear_schedule_with_warmup\nimport torch\nimport gc\nimport torch.nn.init as init\nimport os\nimport matplotlib.pyplot as plt\nclass LossLoggerCallback(TrainerCallback):\n    def __init__(self):\n        self.train_losses = []\n        self.eval_losses = []\n        self.steps = []\n\n    def on_log(self, args, state, control, **kwargs):\n        if 'loss' in state.log_history[-1]:\n            self.train_losses.append(state.log_history[-1]['loss'])\n            self.steps.append(state.global_step)\n        if 'eval_loss' in state.log_history[-1]:\n            self.eval_losses.append(state.log_history[-1]['eval_loss'])\n            \n\ntraining_args = Seq2SeqTrainingArguments(\n        output_dir=\"NLLB_LoRA\",\n        logging_dir=os.getenv(\"WANDB_NAME\")+\"/logs\",\n        evaluation_strategy=\"epoch\",\n        learning_rate=2e-5,\n        save_strategy=\"epoch\",\n        logging_steps=500,\n        per_device_train_batch_size=2,\n        per_device_eval_batch_size=2,\n        weight_decay=0.01,\n        fp16=False,\n        num_train_epochs=7,\n        predict_with_generate=True,\n        load_best_model_at_end=True,\n        gradient_accumulation_steps=4,\n        save_total_limit=2,    \n)\nloss_logger = LossLoggerCallback()\n\ntrainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n        callbacks=[loss_logger],\n)\n\n\ngc.collect()\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T22:03:46.648449Z","iopub.execute_input":"2024-07-31T22:03:46.648885Z","iopub.status.idle":"2024-08-01T02:56:10.260572Z","shell.execute_reply.started":"2024-07-31T22:03:46.648851Z","shell.execute_reply":"2024-08-01T02:56:10.259602Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoudjaramina2001\u001b[0m (\u001b[33mFinalProject_\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240731_220350-csla33y2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/FinalProject_/NLLB/runs/csla33y2' target=\"_blank\">NLLB_LoRA</a></strong> to <a href='https://wandb.ai/FinalProject_/NLLB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/FinalProject_/NLLB' target=\"_blank\">https://wandb.ai/FinalProject_/NLLB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/FinalProject_/NLLB/runs/csla33y2' target=\"_blank\">https://wandb.ai/FinalProject_/NLLB/runs/csla33y2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3059' max='3059' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3059/3059 4:52:00, Epoch 6/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Rouge</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>1.648438</td>\n      <td>31.970100</td>\n      <td>0.568800</td>\n      <td>19.403500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.498600</td>\n      <td>1.349609</td>\n      <td>32.717100</td>\n      <td>0.594600</td>\n      <td>17.435500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.413500</td>\n      <td>1.328125</td>\n      <td>33.177100</td>\n      <td>0.596800</td>\n      <td>17.454500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.387300</td>\n      <td>1.322266</td>\n      <td>33.007300</td>\n      <td>0.597600</td>\n      <td>17.456500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3059, training_loss=1.595777069520779, metrics={'train_runtime': 17541.9641, 'train_samples_per_second': 2.793, 'train_steps_per_second': 0.174, 'total_flos': 4373505925447680.0, 'train_loss': 1.595777069520779, 'epoch': 6.992})"},"metadata":{}}]},{"cell_type":"code","source":"# Plot the training and validation losses\nplt.figure(figsize=(10, 5))\nplt.plot(loss_logger.steps, loss_logger.train_losses, label='Training Loss')\nplt.plot(loss_logger.steps, loss_logger.eval_losses, label='Validation Loss')\nplt.xlabel('Steps')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T02:56:10.262611Z","iopub.execute_input":"2024-08-01T02:56:10.263047Z","iopub.status.idle":"2024-08-01T02:56:11.746901Z","shell.execute_reply.started":"2024-08-01T02:56:10.263008Z","shell.execute_reply":"2024-08-01T02:56:11.744615Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(loss_logger\u001b[38;5;241m.\u001b[39msteps, loss_logger\u001b[38;5;241m.\u001b[39mtrain_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidation Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (7,)"],"ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (6,) and (7,)","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAzoAAAGsCAYAAAAVEdLDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+QklEQVR4nO3de3hU9YH/8c9MJplcJyTkDiEkoKAiiHKLCNrKqrhLy9pWq1ZULru2sK0/W7el3drL9nmwl+2z3W3r7oJKW7VYraBrrSsVgYBBhBIFLygkIQES7pncbzPf3x+TDAkmkAmZnLm8X88zj5mZc2Y+I4eJH7/nfL82Y4wRAAAAAEQQu9UBAAAAAGCoUXQAAAAARByKDgAAAICIQ9EBAAAAEHEoOgAAAAAiDkUHAAAAQMSh6AAAAACIOA6rAwyE1+vV0aNHlZKSIpvNZnUcAAAAABYxxqihoUF5eXmy2/sftwmLonP06FHl5+dbHQMAAABAiKiurtbo0aP7fT4sik5KSook34dxuVwWpwEAAABglfr6euXn5/s7Qn/Couh0n67mcrkoOgAAAAAueEkLkxEAAAAAiDgUHQAAAAARh6IDAAAAIOJQdAAAAABEHIoOAAAAgIhD0QEAAAAQcSg6AAAAACIORQcAAABAxKHoAAAAAIg4FB0AAAAAEYeiAwAAACDiUHQAAAAARByKDgAAAICIQ9EJUPXpZq3fc9jqGAAAAADOw2F1gHBSfbpZN/xss2ySZhWNVG5qgtWRAAAAAPSBEZ0A5KcnavrYNHV6jdZur7Q6DgAAAIB+UHQCtGxOkSTpmZ1VamzrtDgNAAAAgL5QdAL0qQlZKspMUkNrp559u9rqOAAAAAD6QNEJkN1u09LrfKM6T2yrUKfHa3EiAAAAAOei6AzCbVeP0sikOB2pa9Gr79VaHQcAAADAOSg6gxAfG6N7igskSau3lssYY3EiAAAAAD1RdAbpnlkFcjrseuewW29XnrE6DgAAAIAeKDqDNDLZqduuHi1JWl1SbnEaAAAAAD1RdC7CkusKJUl/+eCYKk42WZwGAAAAQDeKzkUYn5WsGydmyRjp8W2M6gAAAAChgqJzkZZ2LSD6/O7DOtPUbnEaAAAAABJF56LNKkrXpFEutXZ49dSOQ1bHAQAAACCKzkWz2Wxa1jWq85vSQ2rt8FicCAAAAABFZwjcemWuclPjdbKxTS+VHbU6DgAAABD1KDpDIDbGrvtnj5UkrdnGAqIAAACA1QIqOqtWrdL06dOVkpKirKwsLVy4UPv37x/w/uvWrZPNZtPChQsDzRnyvjhjjJKdDn10rFFbPjphdRwAAAAgqgVUdLZs2aLly5drx44d2rhxozo6OnTTTTepqenCa8hUVlbqG9/4hubMmTPosKHMFR+rO6bnS5LWlFRYnAYAAACIbjZzEedZnThxQllZWdqyZYvmzp3b73Yej0dz587V4sWLVVJSorq6Om3YsKHf7dva2tTW1ua/X19fr/z8fLndbrlcrsHGDbrDZ5p1/U83y+M1euWrc3R5XuhmBQAAAMJRfX29UlNTL9gNLuoaHbfbLUlKT08/73Y//OEPlZWVpSVLlgzodVetWqXU1FT/LT8//2JiDpvRaYmaPylHku9aHQAAAADWGHTR8Xq9evDBBzV79mxNmjSp3+22bdumxx9/XKtXrx7wa69cuVJut9t/q66uHmzMYdc91fT/vnNUx+pbLU4DAAAARKdBF53ly5dr3759WrduXb/bNDQ06J577tHq1auVkZEx4Nd2Op1yuVy9buFiSv4IzRibrg6P0do3K62OAwAAAEQlx2B2WrFihV5++WVt3bpVo0eP7ne7gwcPqrKyUgsWLPA/5vV6fW/scGj//v0aN27cYCKEtKVzCrWz8rSe3nFIKz41XknOQf1rBgAAADBIAf0XuDFG//RP/6T169dr8+bNKiwsPO/2EydO1N69e3s99i//8i9qaGjQL37xi7C59iZQ8y7LVmFGkipONum5XdW6b/b5/z0BAAAAGFoBFZ3ly5frmWee0YsvvqiUlBTV1tZKklJTU5WQkCBJWrRokUaNGqVVq1YpPj7+E9fvjBgxQpLOe11PuLPbbVp8XaG+u2GfntheqXuKxyrGbrM6FgAAABA1ArpG57HHHpPb7dYNN9yg3Nxc/+3ZZ5/1b1NVVaWampohDxpuPn/1aKUlxqrqdLNee6/W6jgAAABAVLmodXSGy0Dnyg41//bafv3npgO6eswIvfCV2VbHAQAAAMLesKyjg/O7p7hAcTF2/bWqTrsPnbE6DgAAABA1KDpBlJUSr4VT8yRJa0pYQBQAAAAYLhSdIFvatYDo/71Xq6pTzRanAQAAAKIDRSfILs1O0fWXZsprpCe2V1gdBwAAAIgKFJ1hsKxrVOcPu6rlbu6wOA0AAAAQ+Sg6w2D2+JGamJOi5naPnt55yOo4AAAAQMSj6AwDm83mH9VZu71S7Z1eixMBAAAAkY2iM0wWTMlTtsup4w1teumdo1bHAQAAACIaRWeYxDnsuu/aQkm+qabDYJ1WAAAAIGxRdIbRXTPGKDEuRh/WNmjbgZNWxwEAAAAiFkVnGKUmxur2afmSpNUlTDUNAAAABAtFZ5gtua5Qdpu09aMT2l/bYHUcAAAAICJRdIZZfnqibpmUI8l3rQ4AAACAoUfRscDSrqmmXyw7quMNrRanAQAAACIPRccCV49J0zUFaWr3ePXbN1lAFAAAABhqFB2LLJvjm2r6qbcOqbm90+I0AAAAQGSh6Fjkby7PUcHIRNU1d+iPuw9bHQcAAACIKBQdi8TYbVo82zeq8/i2Cnm8LCAKAAAADBWKjoW+MG20UhNiVXmqWX/54JjVcQAAAICIQdGxUGKcQ3fPHCOJqaYBAACAoUTRsdi9145VbIxNb1eeUVl1ndVxAAAAgIhA0bFYtiten5kySpK0mlEdAAAAYEhQdELA0q6ppv+8t0bVp5stTgMAAACEP4pOCLgs16U5l2TIa6Qnt1daHQcAAAAIexSdELF0TpEk6dm3q+Ru6bA4DQAAABDeKDohYu4lGZqQnaKmdo/W7ayyOg4AAAAQ1ig6IcJms2lJ17U6a9+sVIfHa3EiAAAAIHxRdELIZ6/KU2aKUzXuVv3p3Rqr4wAAAABhi6ITQpyOGN1bXCDJN9W0McbiRAAAAEB4ouiEmLtnFig+1q73jtartPyU1XEAAACAsETRCTFpSXH6wjX5kqQ1JRUWpwEAAADCE0UnBC25rlA2m7Tpw+M6cLzB6jgAAABA2KHohKCxGUn6m8uyJUmPb2NUBwAAAAgURSdELZvrW0D0j389opONbRanAQAAAMILRSdETStI05T8EWrv9Oq3pYesjgMAAACEFYpOiLLZbFrWtYDoUzsOqbXDY3EiAAAAIHxQdELYLVfkaHRagk43teuPfz1sdRwAAAAgbFB0Qpgjxq7Fs32jOo+XVMjrZQFRAAAAYCAoOiHu9un5Sol3qPxkkzZ9eNzqOAAAAEBYoOiEuGSnQ3fNHCNJWl1SbnEaAAAAIDxQdMLAfdeOlcNu01sVp7X3sNvqOAAAAEDIo+iEgdzUBC2YkieJUR0AAABgICg6YWJp11TTf9pboyN1LRanAQAAAEIbRSdMXJGXqmvHjZTHa7R2e4XVcQAAAICQRtEJI8vmFEmS1u2sVkNrh8VpAAAAgNBF0Qkj11+aqfFZyWpo69Szb1dbHQcAAAAIWRSdMGK327T0Ot+1Ok9ur1Snx2txIgAAACA0UXTCzMKpo5SRHKcjdS16ZV+t1XEAAACAkETRCTPxsTG6Z9ZYSdKaknIZY6wNBAAAAIQgik4Y+tKsMXI67Hr3sFs7K05bHQcAAAAIORSdMDQy2anPXTNakrS6hKmmAQAAgHNRdMLUkq5JCV7/8JjKTzRanAYAAAAILRSdMDUuM1nzLsuSMdLj2xjVAQAAAHqi6ISxpV0LiD6/+7BON7VbnAYAAAAIHQEVnVWrVmn69OlKSUlRVlaWFi5cqP379593n9WrV2vOnDlKS0tTWlqa5s2bp507d15UaPjMLEzXlaNS1dbp1VM7DlkdBwAAAAgZARWdLVu2aPny5dqxY4c2btyojo4O3XTTTWpqaup3n82bN+vOO+/UG2+8odLSUuXn5+umm27SkSNHLjp8tLPZbFo6x3etzm9LK9Xa4bE4EQAAABAabOYiFmI5ceKEsrKytGXLFs2dO3dA+3g8HqWlpemXv/ylFi1aNKB96uvrlZqaKrfbLZfLNdi4EanD49X1P3lDR92t+vHnrtQd08dYHQkAAAAImoF2g4u6RsftdkuS0tPTB7xPc3OzOjo6zrtPW1ub6uvre93Qt9gYu+6f7RvVWVNSwQKiAAAAgC6i6Hi9Xj344IOaPXu2Jk2aNOD9vvnNbyovL0/z5s3rd5tVq1YpNTXVf8vPzx9szKhwx4x8JTsd+vh4ozZ/dMLqOAAAAIDlBl10li9frn379mndunUD3ufRRx/VunXrtH79esXHx/e73cqVK+V2u/236urqwcaMCq74WH1xuq8MrikptzgNAAAAYL1BFZ0VK1bo5Zdf1htvvKHRo0cPaJ+f/exnevTRR/Xaa69p8uTJ593W6XTK5XL1uuH87r+uUDF2m7YfOKX3jrqtjgMAAABYKqCiY4zRihUrtH79em3atEmFhYUD2u8nP/mJ/vVf/1Wvvvqqpk2bNqigOL9RIxJ065W5knzX6gAAAADRLKCis3z5cj311FN65plnlJKSotraWtXW1qqlpcW/zaJFi7Ry5Ur//R//+Mf67ne/qyeeeEJjx47179PY2Dh0nwKSpGVdU03/7ztHVeNuucDWAAAAQOQKqOg89thjcrvduuGGG5Sbm+u/Pfvss/5tqqqqVFNT02uf9vZ2ff7zn++1z89+9rOh+xSQJE0ePUIzCtPV6TVa+2al1XEAAAAAyzgC2XggUxdv3ry51/3KyspA3gIXadmcIu2sOK1n3qrSP336EiU7A/ojBgAAACLCRa2jg9Bz48QsFWUkqaG1U394m9nqAAAAEJ0oOhHGbrdpSde1Ok9sr1Cnx2txIgAAAGD4UXQi0OeuHq30pDgdPtOi/3vvmNVxAAAAgGFH0YlA8bEx+tKsAknS6pLyAV1bBQAAAEQSik6EWlRcoDiHXWXVddp96IzVcQAAAIBhRdGJUBnJTt02dZQk36gOAAAAEE0oOhFsadekBK+9f0yVJ5ssTgMAAAAMH4pOBBuflaJPTciUMb4Z2AAAAIBoQdGJcMvmFEmSntt1WHXN7RanAQAAAIYHRSfCFY8bqctzXWrp8Ojpt6qsjgMAAAAMC4pOhLPZbFo213etzto3K9XW6bE4EQAAABB8FJ0o8HeT85TjiteJhja9VHbU6jgAAABA0FF0okBsjF33zR4rSXp8WwULiAIAACDiUXSixJ0zxigpLkYf1jao5OOTVscBAAAAgoqiEyVSE2J1+/R8SSwgCgAAgMhH0Ykii2cXym6TSj4+qQ9r662OAwAAAAQNRSeK5Kcnav6kXEnSmhIWEAUAAEDkouhEmaVzfFNNv1h2RMfrWy1OAwAAAAQHRSfKTB2TpmkFaerwGP2mtNLqOAAAAEBQUHSi0NI5RZKkp3ZUqbm90+I0AAAAwNCj6EShv7k8WwUjE+Vu6dDzuw9bHQcAAAAYchSdKBRjt2nJdb5rdR7fViGPlwVEAQAAEFkoOlHq89eMVmpCrA6datbG949ZHQcAAAAYUhSdKJUY59CXZo2RxAKiAAAAiDwUnSh2b/FYxcXYtfvQGf216ozVcQAAAIAhQ9GJYlmueH3mqjxJ0hpGdQAAABBBKDpRrnsB0Vf31ar6dLPFaQAAAIChQdGJchNzXJpzSYa8xjcDGwAAABAJKDrQsq4FRP+wq1ru5g6L0wAAAAAXj6IDzbkkQxNzUtTc7tEzO6usjgMAAABcNIoOZLPZtLRrVGftmxVq7/RanAgAAAC4OBQdSJI+MyVPWSlOHatv08vvHrU6DgAAAHBRKDqQJMU57Lr32rGSpNUlFTLGWBsIAAAAuAgUHfjdPXOMEmJj9EFNvd48eMrqOAAAAMCgUXTgNyIxTrdPGy1JWs0CogAAAAhjFB30svi6Qtls0ub9J/TxsQar4wAAAACDQtFBLwUjk3Tz5TmSpDUlLCAKAACA8ETRwScsm1soSVq/54hONLRZnAYAAAAIHEUHn3BNQbqmjhmhdo9XvyuttDoOAAAAEDCKDvq0rGsB0d/tOKSWdo/FaQAAAIDAUHTQp5uvyFF+eoLONHfoj389bHUcAAAAICAUHfQpxm7T4tm+a3We2FYhr5cFRAEAABA+KDro1+3T8uWKd6j8ZJNe//C41XEAAACAAaPooF9JTofumlkgiQVEAQAAEF4oOjiv+64dK4fdpp0Vp/Xu4Tqr4wAAAAADQtHBeeWkxuszU/IkSatZQBQAAABhgqKDC1raNdX0K3trdKSuxeI0AAAAwIVRdHBBl+e5NHv8SHm8Rk9uY1QHAAAAoY+igwHpHtVZ93a16ls7LE4DAAAAnB9FBwNyw6WZuiQrWY1tnXp2Z7XVcQAAAIDzouhgQGw2m5bO6VpAdHuFOjxeixMBAAAA/aPoYMA+e9UoZSTHqcbdqlf21lgdBwAAAOgXRQcDFh8bo0XFYyX5FhA1xlgbCAAAAOgHRQcB+dKsAsXH2rXvSL12lJ+2Og4AAADQJ4oOApKeFKfPXT1akrSmpNziNAAAAEDfAio6q1at0vTp05WSkqKsrCwtXLhQ+/fvv+B+zz33nCZOnKj4+HhdeeWVeuWVVwYdGNZbcl2hbDbp9Q+P68DxRqvjAAAAAJ8QUNHZsmWLli9frh07dmjjxo3q6OjQTTfdpKampn73efPNN3XnnXdqyZIl2rNnjxYuXKiFCxdq3759Fx0e1ijKTNaNE7MlSY+zgCgAAABCkM1cxBXlJ06cUFZWlrZs2aK5c+f2uc0dd9yhpqYmvfzyy/7HZs2apauuukr/9V//1ec+bW1tamtr89+vr69Xfn6+3G63XC7XYONiCL1Vfkp3/M8OOR12vfmtT2tkstPqSAAAAIgC9fX1Sk1NvWA3uKhrdNxutyQpPT29321KS0s1b968Xo/dfPPNKi0t7XefVatWKTU11X/Lz8+/mJgIghmF6ZoyOlVtnV79bschq+MAAAAAvQy66Hi9Xj344IOaPXu2Jk2a1O92tbW1ys7O7vVYdna2amtr+91n5cqVcrvd/lt1dfVgYyJIfAuIFkmSfld6SK0dHosTAQAAAGc5Brvj8uXLtW/fPm3btm0o80iSnE6nnE5OhQp18yflaNSIBB2pa9H6PUd054wxVkcCAAAAJA1yRGfFihV6+eWX9cYbb2j06NHn3TYnJ0fHjh3r9dixY8eUk5MzmLdGCHHE2HX/7LGSfFNNe70sIAoAAIDQEFDRMcZoxYoVWr9+vTZt2qTCwsIL7lNcXKzXX3+912MbN25UcXFxYEkRku6Ynq8Up0MHTzRp80fHrY4DAAAASAqw6CxfvlxPPfWUnnnmGaWkpKi2tla1tbVqaWnxb7No0SKtXLnSf/9rX/uaXn31Vf3bv/2bPvzwQ33/+9/Xrl27tGLFiqH7FLBMSnys7pzpO2Vt9VammgYAAEBoCKjoPPbYY3K73brhhhuUm5vrvz377LP+baqqqlRTU+O/f+211+qZZ57R//zP/2jKlCl6/vnntWHDhvNOYIDwct+1Y+Ww21Rafkr7jritjgMAAABc3Do6w2Wgc2XDOl9bt0cvlh3Vwqvy9O9fnGp1HAAAAESoYVlHB+i2rGuq6ZffrVGNu+UCWwMAAADBRdHBkJg0KlWzitLV6TVau73S6jgAAACIchQdDJnuUZ1ndlapsa3T4jQAAACIZhQdDJlPTchSUWaSGlo79ezb1VbHAQAAQBSj6GDI2O02Lb3ON6rzxLYKdXq8FicCAABAtKLoYEjddvUojUyK05G6Fr36Xq3VcQAAABClKDoYUvGxMfrSrAJJ0uqSCoXB7OUAAACIQBQdDLl7igsU57Drneo67Tp0xuo4AAAAiEIUHQy5jGSnPnf1KEnS6q3lFqcBAABANKLoICiWdE1KsPGDY6o42WRxGgAAAEQbig6CYnxWsj49MUvG+GZgAwAAAIYTRQdBs3ROoSTpud3VOtPUbnEaAAAARBOKDoKmuGikrshzqbXDq6d2HLI6DgAAAKIIRQdBY7PZtGyO71qd35QeUmuHx+JEAAAAiBYUHQTV307OVW5qvE42tumlsqNWxwEAAECUoOggqGJj7Lrv2rGSpDXbyllAFAAAAMOCooOg++KMMUqKi9FHxxq15aMTVscBAABAFKDoIOhSE2J1x/QxkqQ1JUw1DQAAgOCj6GBY3D97rOw2aduBk3r/aL3VcQAAABDhKDoYFvnpiZp/Za4k37U6AAAAQDBRdDBsuqea/t93jupYfavFaQAAABDJKDoYNlflj9CMsenq8BitfbPS6jgAAACIYBQdDKulcwolSU/vOKSmtk6L0wAAACBSUXQwrOZdlq3CjCTVt3bquV3VVscBAABAhKLoYFjZ7TYtvs43qvPE9kp5vCwgCgAAgKFH0cGw+/zVo5WWGKuq08167b1aq+MAAAAgAlF0MOwS4mL0pVkFkqTVJUw1DQAAgKFH0YEl7ikuUFyMXX+tqtPuQ2esjgMAAIAIQ9GBJbJS4rVwap4kaQ2jOgAAABhiFB1YZmnXAqL/916tqk41W5wGAAAAkYSiA8tcmp2i6y/NlNdIT2yvsDoOAAAAIghFB5Za1jWq84dd1XI3d1icBgAAAJGCogNLzR4/UhNzUtTc7tHTOw9ZHQcAAAARgqIDS9lsNv+ozm/erFR7p9fiRAAAAIgEFB1YbsGUPGW7nDpW36b/feeo1XEAAAAQASg6sFycw657rx0rybeAqDHG2kAAAAAIexQdhIS7ZxQoMS5GH9Y2aPuBU1bHAQAAQJij6CAkpCbG6vZp+ZJ8ozoAAADAxaDoIGQsnl0ou03a8tEJ7a9tsDoOAAAAwhhFByFjzMhE3XxFjiRpDaM6AAAAuAgUHYSUpV1TTb9YdlTHG1otTgMAAIBwRdFBSLmmIE1Xjxmhdo9Xv32TBUQBAAAwOBQdhJzuBUSfeuuQmts7LU4DAACAcETRQci56YocjUlPVF1zh/64+7DVcQAAABCGKDoIOTF2mxbPHitJenxbhTxeFhAFAABAYCg6CElfmJYvV7xDlaea9ZcPjlkdBwAAAGGGooOQlOR06O5ZBZKYahoAAACBo+ggZN137VjFxtj0duUZlVXXWR0HAAAAYYSig5CV7YrXgil5kqTVjOoAAAAgABQdhLTuqab/vLdG1aebLU4DAACAcEHRQUi7LNelOZdkyGukJ7dXWh0HAAAAYYKig5C3tGtU59m3q+Ru6bA4DQAAAMIBRQchb+4lGZqQnaKmdo/W7ayyOg4AAADCAEUHIc9ms2nJnEJJ0to3K9Xh8VqcCAAAAKEu4KKzdetWLViwQHl5ebLZbNqwYcMF93n66ac1ZcoUJSYmKjc3V4sXL9apU6cGkxdR6rNX5Skzxakad6v+9G6N1XEAAAAQ4gIuOk1NTZoyZYp+9atfDWj77du3a9GiRVqyZInee+89Pffcc9q5c6eWLVsWcFhEL6cjRvcW+xYQXV1SLmOMxYkAAAAQyhyB7jB//nzNnz9/wNuXlpZq7Nix+upXvypJKiws1D/+4z/qxz/+caBvjSh398wC/fKNA3rvaL1Ky0/p2nEZVkcCAABAiAr6NTrFxcWqrq7WK6+8ImOMjh07pueff1633nprv/u0tbWpvr6+1w1IS4rTF67JlyStKamwOA0AAABCWdCLzuzZs/X000/rjjvuUFxcnHJycpSamnreU99WrVql1NRU/y0/Pz/YMREmllxXKJtN2vThcR043mB1HAAAAISooBed999/X1/72tf0yCOPaPfu3Xr11VdVWVmpBx54oN99Vq5cKbfb7b9VV1cHOybCxNiMJP3NZdmSpMe3MaoDAACAvgV8jU6gVq1apdmzZ+vhhx+WJE2ePFlJSUmaM2eOfvSjHyk3N/cT+zidTjmdzmBHQ5haNrdIr71/TH/86xF9/aYJykjmWAEAAEBvQR/RaW5ult3e+21iYmIkiZmzMCjTCtI0JX+E2ju9+l3pIavjAAAAIAQFXHQaGxtVVlamsrIySVJFRYXKyspUVeVbsX7lypVatGiRf/sFCxbohRde0GOPPaby8nJt375dX/3qVzVjxgzl5eUNzadAVLHZbFrWtYDo73YcUmuHx+JEAAAACDUBF51du3Zp6tSpmjp1qiTpoYce0tSpU/XII49IkmpqavylR5Luu+8+/fznP9cvf/lLTZo0SV/4whc0YcIEvfDCC0P0ERCNbrkiR6NGJOh0U7te+OsRq+MAAAAgxNhMGJw/Vl9fr9TUVLndbrlcLqvjIEQ8vq1C//ry+yrKTNJf/t/1stttVkcCAABAkA20GwT9Gh0gWO6Ynq+UeIfKTzRp04fHrY4DAACAEELRQdhKdjp014wxkqTVJeUWpwEAAEAooeggrN03e6wcdpveqjitvYfdVscBAABAiKDoIKzlpibo7yb71mJiVAcAAADdKDoIe0vnFEmS/rS3RkfqWixOAwAAgFBA0UHYmzQqVcVFI+XxGq3dXmF1HAAAAIQAig4iwrK5vgVE1+2sVkNrh8VpAAAAYDWKDiLCDZdmaVxmkhraOvXs29VWxwEAAIDFKDqICHa7zX+tzpPbK9Xp8VqcCAAAAFai6CBi/P3UURqZFKcjdS16ZV+t1XEAAABgIYoOIkZ8bIzuKS6QJK0pKZcxxuJEAAAAsApFBxHlnlkFcjrsevewWzsrTlsdBwAAABah6CCijEx26rarR0uSVpcw1TQAAEC0ougg4iyd45tq+vUPj6n8RKPFaQAAAGAFig4izrjMZM27LEvGSI9vY1QHAAAgGlF0EJG6p5p+fvdhnW5qtzgNAAAAhhtFBxFpZmG6rhyVqrZOr57accjqOAAAABhmFB1EJJvN5r9W57ellWrt8FicCAAAAMOJooOIdeuVucpLjdfJxna9WHbE6jgAAAAYRhQdRKzYGLvun+0b1VlTUsECogAAAFGEooOIdseMfCU7Hfr4eKM2f3TC6jgAAAAYJhQdRDRXfKy+OD1fkrSmpNziNAAAABguFB1EvPuvK1SM3abtB07pvaNuq+MAAABgGFB0EPFGjUjQrVfmSpIeL2EBUQAAgGhA0UFUWNY11fRL7xxVrbvV4jQAAAAINooOosLk0SM0ozBdnV6jtW9WWh0HAAAAQUbRQdRYNqdIkvTMW4fU2NZpcRoAAAAEE0UHUePGiVkqykhSfWun/vB2tdVxAAAAEEQUHUQNu92mxdf5rtV5YnuFOj1eixMBAAAgWCg6iCqfu3q00hJjdfhMi/7vvWNWxwEAAECQUHQQVRLiYnTPrAJJ0uqSchljLE4EAACAYKDoIOrcUzxWcQ67yqrrtPvQGavjAAAAIAgoOog6mSlO/f1VoyT5RnUAAAAQeSg6iEpLuxYQfe39Y6o82WRxGgAAAAw1ig6i0iXZKbphQqaM8c3ABgAAgMhC0UHU6l5A9Lldh1XX3G5xGgAAAAwlig6i1rXjRuqyXJdaOjx6+q0qq+MAAABgCFF0ELVsNpuWdV2rs/bNSrV1eixOBAAAgKFC0UFU+7vJecp2OXWioU0vlR21Og4AAACGCEUHUS3OYdd91/pGdR7fVsECogAAABGCooOod9eMMUqMi9GHtQ0q+fik1XEAAAAwBCg6iHqpibG6fVq+JBYQBQAAiBQUHUDSkusKZbdJJR+f1Ie19VbHAQAAwEWi6ACS8tMTNX9SriRpTQkLiAIAAIQ7ig7QZWnXVNMvlh3R8fpWi9MAAADgYlB0gC5Tx6RpWkGaOjxGvymttDoOAAAALgJFB+hh6ZwiSdJTO6rU3N5pcRoAAAAMFkUH6OFvLs9WwchEuVs69Pzuw1bHAQAAwCBRdIAeYuw2Lbnu7AKiHi8LiAIAAIQjig5wjs9fM1qpCbE6dKpZG98/ZnUcAAAADAJFBzhHYpxDX5o1RpK0hgVEAQAAwhJFB+jDvcVjFRdj165DZ7Sn6ozVcQAAABAgig7QhyxXvD5zVZ4kFhAFAAAIRxQdoB/dC4j+eV+Nqk83W5wGAAAAgQi46GzdulULFixQXl6ebDabNmzYcMF92tra9J3vfEcFBQVyOp0aO3asnnjiicHkBYbNxByX5lySIa/xzcAGAACA8BFw0WlqatKUKVP0q1/9asD73H777Xr99df1+OOPa//+/fr973+vCRMmBPrWwLBb1rWA6B92Vcvd3GFxGgAAAAyUI9Ad5s+fr/nz5w94+1dffVVbtmxReXm50tPTJUljx44N9G0BS8y5JEMTc1L0YW2DntlZpS/fMM7qSAAAABiAoF+j89JLL2natGn6yU9+olGjRunSSy/VN77xDbW0tPS7T1tbm+rr63vdACvYbGcXEF37ZoXaO70WJwIAAMBABL3olJeXa9u2bdq3b5/Wr1+vf//3f9fzzz+vr3zlK/3us2rVKqWmpvpv+fn5wY4J9OszV+UpM8WpY/Vtevndo1bHAQAAwAAEveh4vV7ZbDY9/fTTmjFjhm699Vb9/Oc/129+85t+R3VWrlwpt9vtv1VXVwc7JtAvpyNG9107VpK0uqRCxhhrAwEAAOCCgl50cnNzNWrUKKWmpvofu+yyy2SM0eHDh/vcx+l0yuVy9boBVrp75hglxMbog5p6vXnwlNVxAAAAcAFBLzqzZ8/W0aNH1djY6H/so48+kt1u1+jRo4P99sCQGJEYpy9M8x2vq0vKLU4DAACACwm46DQ2NqqsrExlZWWSpIqKCpWVlamqqkqS77SzRYsW+be/6667NHLkSN1///16//33tXXrVj388MNavHixEhIShuZTAMNg8exC2WzS5v0n9PGxBqvjAAAA4DwCLjq7du3S1KlTNXXqVEnSQw89pKlTp+qRRx6RJNXU1PhLjyQlJydr48aNqqur07Rp03T33XdrwYIF+o//+I8h+gjA8BibkaSbLs+WJK0pYQFRAACAUGYzYXBldX19vVJTU+V2u7leB5baVXlan/+vUsXF2LX9W59WZorT6kgAAABRZaDdIOjX6ACR5JqCNF2VP0LtHq9+V1ppdRwAAAD0g6IDBMBms2nZnCJJ0u92HFJLu8fiRAAAAOgLRQcI0M1XZGt0WoLONHfoj3/te4p0AAAAWIuiAwTIEWPX4tmFkqQntlXI6w35y9wAAACiDkUHGITbp+crJd6h8pNNev3D41bHAQAAwDkoOsAgJDsdumvmGEksIAoAABCKKDrAIN1/baEcdpt2VpzWu4frrI4DAACAHig6wCDlpMbrM1PyJEmrWUAUAAAgpFB0gIuwtGuq6Vf21uhIXYvFaQAAANCNogNchMvzXJo9fqQ8XqMntzGqAwAAECooOsBF6h7VWfd2tepbOyxOAwAAAImiA1y0Gy7N1CVZyWps69SzO6utjgMAAABRdICLZrPZtHSObwHRJ7dXqMPjtTgRAAAAKDrAEPjsVaOUkRyno+5WvbK3xuo4AAAAUY+iAwyB+NgYLSoeK0laU1IhY4y1gQAAAKIcRQcYIl+aVaD4WLv2HnHrrYrTVscBAACIahQdYIikJ8Xpc1ePliSt3lpucRoAAIDoRtEBhtCS6wpls0mvf3hcB443Wh0HAAAgalF0gCFUlJmsGydmS5IeZwFRAAAAy1B0gCG2rGuq6Rf+elinGtssTgMAABCdKDrAEJtRmK7Jo1PV1unV73YcsjoOAABAVKLoAEPMt4BokSTpd6WH1NrhsTgRAABA9KHoAEFw66QcjRqRoFNN7Vq/54jVcQAAAKIORQcIAkeMXffPHitJWlNSLq+XBUQBAACGE0UHCJI7pucrxenQwRNN2vzRcavjAAAARBWKDhAkKfGx+uKMfEnSqlc+1GObD+r/3qvVgeMNau/0WpwOAAAgstmMMSF/Tk19fb1SU1PldrvlcrmsjgMM2NG6Fl3/0zfU4en91yzGbtOY9EQVZSRpXFayijKSVJSZrHGZSUpPipPNZrMoMQAAQGgbaDeg6ABBtvvQGW0/cFIHTzSq/ESTyk80qqm9/5nYUhNiVZSZpHGZyf5/jstM0pj0JMU5GIQFAADRjaIDhChjjI7Vt6n8RKMOnmjUwRNNKj/ZpIPHG3XU3aL+/kb2HAU6W4R8ZWgko0AAACBKUHSAMNTa4VHFyaZeoz8HAxgFKspI1risrn9mJqlgJKNAAAAgslB0gAjSaxSoa/Sn/KSvAB2pO/8oUH5agv80ON91QIwCAQCA8EXRAaJE9yhQ+YnukaCBjQK54h1dEyH0vhaIUSAAABDKKDpAlDPG6HhDmw4e940C9SxA5xsFstvkuxYoM7nXrHDjspIZBQIAAJaj6ADoV1+jQN0TIlxoFKjn6W/jukaCxoxMlNMRM4yfAAAARCuKDoCA+UeBeoz+dJehC40C5acn+gpQjzWBijKTlZHMKBAAABg6FB0AQ6q1w6PKU006eLzp7AhQVxFqbOvsd7/uUaCe1wEVZSargFEgAAAwCBQdAMPCGKMTDW060GP0p/xEk8pPNurwmQuPAhVl9F4TaByjQAAA4DwoOgAs1z0KVH6i95TYBy8wCpTivxaIUSAAANAbRQdAyDp3FMg/EhTAKFDPSRGKMpOUmexkFAgAgChA0QEQlnqOAvWcEnvAo0A9psTuHgWKj2UUCACASEHRARBRukeBDp5zHdDBExceBRqdlug//a37OiBGgQAACE8UHQBRo7XDo0Onms+uCdSjDDWcbxTI6VBRlm8U6GwBYhQIAIBQRtEBEPV6jgKVn2z0TY190leAqs80X3AUqCgzSUUZyRqXdfafjAIBAGAtig4AnEf3KJDv+p8AR4F6nP7WPSkCo0AAAAwPig4ADIIxRica23qN/nQXoMNnmuXt5xvTZpNGpyX4ClBG7wVSM1MYBQIAYKhQdABgiPUcBSo/6Vsb6GDX2kANrRceBSrqsSZQUWaSxo5MYhQIAIAAUXQAYJh0jwL1HP3pnhJ7IKNARRm91wQan5msjGSn7HZGgQAAOBdFBwBCQFtn14xwx7tGgXqsDXS+USBJSoiNUWJcjBKdMUqMdSghrut+XIwS4xxKjIvp8ZjD/1xCnENJ/uccn9jH6bBzKh0AIGwNtBs4hjETAEQdpyNGl2an6NLslF6PG2N0srH9nIkQfGWo+rRvFKilw6OWDo9ONQ1tJrtNSow7W5wSYmOU5HT4f+5Zlrp/7qtgJcV9snzFOexDGxYAgEGi6ACABWw2mzJTnMpMcWpW0chez7V1elTf0qmWdo+a2jvV3O5RS7tHzV0/N3f97Hveo5buxzt82zW1daqlw+Pfr/s12ju9kiSvkRrbOtV4ntnlBstht/nLT88i1HuUyVeKfAWrq0j5R696F64kZ9drxMbIEUOJAgAMHEUHAEKM0xGjzJShn6Sg0+P1F6B+y1KPctTS3ntbf+Hq6FRzW4/X6PCow+M7C7rTa9TQ2tl1Wl7bkOaPi7F3ncbX92l5vlGm3iNQ/Y08nT3tz1eyuB4KACIPRQcAooQjxq6UGLtS4mOH/LXbO71nS1D72ZGl7lGm5nNGpFraO7sKVu8S1bN0dReu7skc2j1etTd7VaeOIc8fH2s//yhT7NnRqCSno8cpfr6y1N81UfGxXA8FAFah6AAALlqcw644h12pGtoSZYxRm79EedTc1qMsdXSqqa1HWfKfuud7rs/RqJ73Ozzqno6ntcOr1o72Ic0u+WbW85WiAEaZYs+ewuc7jc/RVbDOFrAEJpUAgAui6AAAQpbNZlN8bIziY2OUNsSvbYxRa4e332ufmnudvtf71L5epauja4SqzdN1amCnWju8Xe8h/35DLcZu6zXSFOewy2G3yxFjU4zdpli7XTF2mxwxNjnsNsXY7XKccz+2a1vf4/aux3v/7NvmAvva7YqJOftzfxm6t4vtfp8e23a/H+UNwFCh6AAAopLN5ps4ISEuRiMvvHlAPF7jLz39Xus0gNP5epav5q7rq7onlfB4jRraOtUQhEklrHS2YNl7lLCuknSBsnW2NHUVNX+punDJ66vw9Vfyzv58NielDgg9ARedrVu36qc//al2796tmpoarV+/XgsXLhzQvtu3b9f111+vSZMmqaysLNC3BgAgLMTYbUp2OpTsHPr/n9jp8fa69ql7lr2OTq86vUadXq86PUYer1GH18jTdd/3nJHH4z37s9eow+OVp+t+Z9dzvse79vUa/+t19nitT+zb432773s83RnOvnb3vp5+VtLt3qatq9BFMqtLXYJ/hsNPTuzRc+ZEpo1HuAr4G7ipqUlTpkzR4sWLddtttw14v7q6Oi1atEg33nijjh07FujbAgAA+SaVcMXY5QrCpBLDyes18pi+ylZXSfKXrU8WrN6FrO+y1dFHqet+7QuVvIFk6N7X916+UtfZ47XOFs3wL3WBTBvfc+HixJ6TezBtPCwQcNGZP3++5s+fH/AbPfDAA7rrrrsUExOjDRs2BLw/AACIHHa7TXbZFBsjxccO/XTqocSYHmXrfEWtr4IVrFLnMWrt7Do9su2TMyYybTwiwbBco/Pkk0+qvLxcTz31lH70ox9dcPu2tja1tZ39i1RfXx/MeAAAAEFjs/mu9wm3Ptfh8faztlbva8ua+5kavs/ZDruuN+se5bJq2viBlCWmjQ9/QS86H3/8sb71rW+ppKREDsfA3m7VqlX6wQ9+EORkAAAA6E9sjF2pCXalJgz9tPHtHm/XSFKPsnTu1PDnXYvrkwsbt3RNMz9808afW47OOX0v1tFVsLqmjY9z+Eavekwbf+5aXUwbP7SCWnQ8Ho/uuusu/eAHP9Cll1464P1Wrlyphx56yH+/vr5e+fn5wYgIAACAYWSz2eR0xMjpGN5p45vPKUctHV0LG59n2vier9H3tPFDW6TsNgV2HVQ/a3H5r4OKi1FirK9gxUbh9VBBLToNDQ3atWuX9uzZoxUrVkiSvF6vjDFyOBx67bXX9OlPf/oT+zmdTjmdzmBGAwAAQIQJ5rTx3q5p488dSQp02vjugtXXtPFeo6BNGx8bYzs7y57zbAnqu0T1fWpfTmq8Ls1OGfJswRLUouNyubR3795ej/3617/Wpk2b9Pzzz6uwsDCYbw8AAAAMCbvdpiSnQ0nDOG28vyy19T3K1O91UD1Grzq7rofq8Bh1eDpV3zr4EjV/Uo4e+9I1Q/Wxgy7gP6nGxkYdOHDAf7+iokJlZWVKT0/XmDFjtHLlSh05ckS//e1vZbfbNWnSpF77Z2VlKT4+/hOPAwAAANEomNPGt3d6+5gg4pxT+zp6XBflP3Wvd+FqbvdoTHrikOcLpoCLzq5du/SpT33Kf7/7Wpp7771Xa9euVU1NjaqqqoYuIQAAAIBBiXPYFeewKzUxvNfeGgybMabvVaxCSH19vVJTU+V2u+VyuayOAwAAAMAiA+0G0Tf9AgAAAICIR9EBAAAAEHEoOgAAAAAiDkUHAAAAQMSh6AAAAACIOBQdAAAAABGHogMAAAAg4lB0AAAAAEQcig4AAACAiEPRAQAAABBxKDoAAAAAIg5FBwAAAEDEoegAAAAAiDgOqwMMhDFGklRfX29xEgAAAABW6u4E3R2hP2FRdBoaGiRJ+fn5FicBAAAAEAoaGhqUmpra7/M2c6EqFAK8Xq+OHj2qlJQU2Ww2S7PU19crPz9f1dXVcrlclmZBeOCYQaA4ZhAojhkEimMGgQqlY8YYo4aGBuXl5clu7/9KnLAY0bHb7Ro9erTVMXpxuVyW/yEjvHDMIFAcMwgUxwwCxTGDQIXKMXO+kZxuTEYAAAAAIOJQdAAAAABEHIpOgJxOp773ve/J6XRaHQVhgmMGgeKYQaA4ZhAojhkEKhyPmbCYjAAAAAAAAsGIDgAAAICIQ9EBAAAAEHEoOgAAAAAiDkUHAAAAQMSh6AAAAACIOBQdSd///vdls9l63SZOnOh/vrW1VcuXL9fIkSOVnJysz33uczp27Fiv16iqqtLf/u3fKjExUVlZWXr44YfV2dk53B8FQbJ161YtWLBAeXl5stls2rBhQ6/njTF65JFHlJubq4SEBM2bN08ff/xxr21Onz6tu+++Wy6XSyNGjNCSJUvU2NjYa5t3331Xc+bMUXx8vPLz8/WTn/wk2B8NQXKhY+a+++77xPfOLbfc0msbjpnosWrVKk2fPl0pKSnKysrSwoULtX///l7bDNXvos2bN+vqq6+W0+nU+PHjtXbt2mB/PATBQI6ZG2644RPfMw888ECvbThmosdjjz2myZMny+VyyeVyqbi4WH/+85/9z0fkd4yB+d73vmeuuOIKU1NT47+dOHHC//wDDzxg8vPzzeuvv2527dplZs2aZa699lr/852dnWbSpElm3rx5Zs+ePeaVV14xGRkZZuXKlVZ8HATBK6+8Yr7zne+YF154wUgy69ev7/X8o48+alJTU82GDRvMO++8Yz7zmc+YwsJC09LS4t/mlltuMVOmTDE7duwwJSUlZvz48ebOO+/0P+92u012dra5++67zb59+8zvf/97k5CQYP77v/97uD4mhtCFjpl7773X3HLLLb2+d06fPt1rG46Z6HHzzTebJ5980uzbt8+UlZWZW2+91YwZM8Y0Njb6txmK30Xl5eUmMTHRPPTQQ+b99983//mf/2liYmLMq6++OqyfFxdvIMfM9ddfb5YtW9bre8btdvuf55iJLi+99JL505/+ZD766COzf/9+8+1vf9vExsaaffv2GWMi8zuGomN8RWfKlCl9PldXV2diY2PNc88953/sgw8+MJJMaWmpMcb3HzR2u93U1tb6t3nssceMy+UybW1tQc2O4Xfuf7R6vV6Tk5NjfvrTn/ofq6urM06n0/z+9783xhjz/vvvG0nm7bff9m/z5z//2dhsNnPkyBFjjDG//vWvTVpaWq9j5pvf/KaZMGFCkD8Rgq2/ovPZz3623304ZqLb8ePHjSSzZcsWY8zQ/S7653/+Z3PFFVf0eq877rjD3HzzzcH+SAiyc48ZY3xF52tf+1q/+3DMIC0tzaxZsyZiv2M4da3Lxx9/rLy8PBUVFenuu+9WVVWVJGn37t3q6OjQvHnz/NtOnDhRY8aMUWlpqSSptLRUV155pbKzs/3b3Hzzzaqvr9d77703vB8Ew66iokK1tbW9jpHU1FTNnDmz1zEyYsQITZs2zb/NvHnzZLfb9dZbb/m3mTt3ruLi4vzb3Hzzzdq/f7/OnDkzTJ8Gw2nz5s3KysrShAkT9OUvf1mnTp3yP8cxE93cbrckKT09XdLQ/S4qLS3t9Rrd23S/BsLXucdMt6effloZGRmaNGmSVq5cqebmZv9zHDPRy+PxaN26dWpqalJxcXHEfsc4LHnXEDNz5kytXbtWEyZMUE1NjX7wgx9ozpw52rdvn2praxUXF6cRI0b02ic7O1u1tbWSpNra2l5/6N3Pdz+HyNb9Z9zXMdDzGMnKyur1vMPhUHp6eq9tCgsLP/Ea3c+lpaUFJT+sccstt+i2225TYWGhDh48qG9/+9uaP3++SktLFRMTwzETxbxerx588EHNnj1bkyZNkqQh+13U3zb19fVqaWlRQkJCMD4SgqyvY0aS7rrrLhUUFCgvL0/vvvuuvvnNb2r//v164YUXJHHMRKO9e/equLhYra2tSk5O1vr163X55ZerrKwsIr9jKDqS5s+f7/958uTJmjlzpgoKCvSHP/yBv8AAguKLX/yi/+crr7xSkydP1rhx47R582bdeOONFiaD1ZYvX659+/Zp27ZtVkdBmOjvmPmHf/gH/89XXnmlcnNzdeONN+rgwYMaN27ccMdECJgwYYLKysrkdrv1/PPP695779WWLVusjhU0nLrWhxEjRujSSy/VgQMHlJOTo/b2dtXV1fXa5tixY8rJyZEk5eTkfGJWiu773dsgcnX/Gfd1DPQ8Ro4fP97r+c7OTp0+fZrjCJKkoqIiZWRk6MCBA5I4ZqLVihUr9PLLL+uNN97Q6NGj/Y8P1e+i/rZxuVz8j70w1d8x05eZM2dKUq/vGY6Z6BIXF6fx48frmmuu0apVqzRlyhT94he/iNjvGIpOHxobG3Xw4EHl5ubqmmuuUWxsrF5//XX/8/v371dVVZWKi4slScXFxdq7d2+v/yjZuHGjXC6XLr/88mHPj+FVWFionJycXsdIfX293nrrrV7HSF1dnXbv3u3fZtOmTfJ6vf5fPMXFxdq6das6Ojr822zcuFETJkzgFKQocPjwYZ06dUq5ubmSOGaijTFGK1as0Pr167Vp06ZPnJI4VL+LiouLe71G9zbdr4HwcaFjpi9lZWWS1Ot7hmMmunm9XrW1tUXud4wlUyCEmK9//etm8+bNpqKiwmzfvt3MmzfPZGRkmOPHjxtjfNPtjRkzxmzatMns2rXLFBcXm+LiYv/+3dPt3XTTTaasrMy8+uqrJjMzk+mlI0hDQ4PZs2eP2bNnj5Fkfv7zn5s9e/aYQ4cOGWN800uPGDHCvPjii+bdd981n/3sZ/ucXnrq1KnmrbfeMtu2bTOXXHJJr6mC6+rqTHZ2trnnnnvMvn37zLp160xiYiJTBYep8x0zDQ0N5hvf+IYpLS01FRUV5i9/+Yu5+uqrzSWXXGJaW1v9r8ExEz2+/OUvm9TUVLN58+ZeUwE3Nzf7txmK30XdU78+/PDD5oMPPjC/+tWvmCo4TF3omDlw4ID54Q9/aHbt2mUqKirMiy++aIqKiszcuXP9r8ExE12+9a1vmS1btpiKigrz7rvvmm9961vGZrOZ1157zRgTmd8xFB3jm/YuNzfXxMXFmVGjRpk77rjDHDhwwP98S0uL+cpXvmLS0tJMYmKi+fu//3tTU1PT6zUqKyvN/PnzTUJCgsnIyDBf//rXTUdHx3B/FATJG2+8YSR94nbvvfcaY3xTTH/3u9812dnZxul0mhtvvNHs37+/12ucOnXK3HnnnSY5Odm4XC5z//33m4aGhl7bvPPOO+a6664zTqfTjBo1yjz66KPD9RExxM53zDQ3N5ubbrrJZGZmmtjYWFNQUGCWLVvWa8pOYzhmoklfx4ok8+STT/q3GarfRW+88Ya56qqrTFxcnCkqKur1HggfFzpmqqqqzNy5c016erpxOp1m/Pjx5uGHH+61jo4xHDPRZPHixaagoMDExcWZzMxMc+ONN/pLjjGR+R1jM8aY4Rs/AgAAAIDg4xodAAAAABGHogMAAAAg4lB0AAAAAEQcig4AAACAiEPRAQAAABBxKDoAAAAAIg5FBwAAAEDEoegAAAAAiDgUHQAAAAARh6IDAAAAIOJQdAAAAABEnP8PU5oJxKMKpyAAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"import math\n\neval_results=trainer.evaluate() \nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T03:06:19.221507Z","iopub.execute_input":"2024-08-01T03:06:19.221923Z","iopub.status.idle":"2024-08-01T03:35:39.743711Z","shell.execute_reply.started":"2024-08-01T03:06:19.221892Z","shell.execute_reply":"2024-08-01T03:35:39.742573Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 29:10]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 3.75\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.model.save_pretrained(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T03:35:50.698103Z","iopub.execute_input":"2024-08-01T03:35:50.698499Z","iopub.status.idle":"2024-08-01T03:35:50.754114Z","shell.execute_reply.started":"2024-08-01T03:35:50.698466Z","shell.execute_reply":"2024-08-01T03:35:50.752678Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[43msave_path\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'save_path' is not defined"],"ename":"NameError","evalue":"name 'save_path' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#### peft_model.config.use_cache=True\ncontext=tokenizer([\"Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©\"], return_tensors=\"pt\")\noutput=model.generate(**context)\n\ntokenizer.decode(output[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T03:35:58.118214Z","iopub.execute_input":"2024-08-01T03:35:58.118599Z","iopub.status.idle":"2024-08-01T03:35:58.805860Z","shell.execute_reply.started":"2024-08-01T03:35:58.118569Z","shell.execute_reply":"2024-08-01T03:35:58.804640Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1797: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'Saudi Arabia.'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntrainer.push_to_hub(os.getenv(\"WANDB_NAME\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T03:37:03.980327Z","iopub.execute_input":"2024-08-01T03:37:03.980717Z","iopub.status.idle":"2024-08-01T03:37:04.777927Z","shell.execute_reply.started":"2024-08-01T03:37:03.980680Z","shell.execute_reply":"2024-08-01T03:37:04.776621Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWANDB_NAME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:914\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    912\u001b[0m organization \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 914\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# Create a new empty model card and eventually tag it\u001b[39;00m\n\u001b[1;32m    919\u001b[0m model_card \u001b[38;5;241m=\u001b[39m create_and_tag_model_card(\n\u001b[1;32m    920\u001b[0m     repo_id, tags, token\u001b[38;5;241m=\u001b[39mtoken, ignore_metadata_errors\u001b[38;5;241m=\u001b[39mignore_metadata_errors\n\u001b[1;32m    921\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:730\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    727\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    728\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 730\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mrepo_id\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3256\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3253\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3256\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3259\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-66ab02e0-6155a20068a97ace13c4caa7;e1ee83e7-fba6-46c4-9c92-fd8033baaec1)\n\nInvalid username or password."],"ename":"HfHubHTTPError","evalue":"401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-66ab02e0-6155a20068a97ace13c4caa7;e1ee83e7-fba6-46c4-9c92-fd8033baaec1)\n\nInvalid username or password.","output_type":"error"}]}]}